{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Grandient Descent using NumPy\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# f = w*x\r\n",
    "# f = 2*x\r\n",
    "\r\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\r\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\r\n",
    "\r\n",
    "w = 0.0\r\n",
    "\r\n",
    "#forwardpass\r\n",
    "def forward(x):\r\n",
    "    return w * x\r\n",
    "\r\n",
    "#loss = MSE\r\n",
    "def loss(y, y_predicted):\r\n",
    "    return ((y_predicted - y) ** 2).mean()\r\n",
    "\r\n",
    "#gradient\r\n",
    "#MSE = 1/N * (w*x - y)**2\r\n",
    "#dJ/dw = 1/N * 2x(w*x - y)\r\n",
    "def gradient(x,y,y_predicted):\r\n",
    "    return np.dot(2*x, y_predicted - y).mean()\r\n",
    "\r\n",
    "print(forward(5))\r\n",
    "\r\n",
    "#training\r\n",
    "learning_rate = 0.01\r\n",
    "n_iters = 20\r\n",
    "\r\n",
    "for epoch in range(n_iters):\r\n",
    "    y_pred = forward(X)\r\n",
    "    \r\n",
    "    l = loss(Y, y_pred)\r\n",
    "    \r\n",
    "    dw = gradient(X,Y,y_pred)\r\n",
    "    \r\n",
    "    w -= learning_rate * dw\r\n",
    "print(forward(5))\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n",
      "9.999999976158142\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import torch \r\n",
    "\r\n",
    "# f = w*x\r\n",
    "# f = 2*x\r\n",
    "\r\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\r\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\r\n",
    "\r\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad= True)\r\n",
    "\r\n",
    "#forwardpass\r\n",
    "def forward(x):\r\n",
    "    return w * x\r\n",
    "\r\n",
    "#loss = MSE\r\n",
    "def loss(y, y_predicted):\r\n",
    "    return ((y_predicted - y) ** 2).mean()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print(forward(5))\r\n",
    "\r\n",
    "#training\r\n",
    "learning_rate = 0.01\r\n",
    "n_iters = 76\r\n",
    "\r\n",
    "for epoch in range(n_iters):\r\n",
    "    y_pred = forward(X)\r\n",
    "    \r\n",
    "    l = loss(Y, y_pred)\r\n",
    "    \r\n",
    "    #gradient = backwardpass\r\n",
    "    l.backward()\r\n",
    "    with torch.no_grad():\r\n",
    "        w -= learning_rate * w.grad\r\n",
    "    w.grad.zero_()\r\n",
    "    \r\n",
    "print(forward(5))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0., grad_fn=<MulBackward0>)\n",
      "tensor(9.9999, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#trainig pipeline tutorial\r\n",
    "# 1) training model(input, output size, forwardpass)\r\n",
    "# 2) construct loss and optimizer\r\n",
    "# 3) trainig pipeline\r\n",
    "# - forwardpass - compute prediction\r\n",
    "# - backwardpass - gradient\r\n",
    "# - update weights\r\n",
    "\r\n",
    "import torch\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}